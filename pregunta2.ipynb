{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importación de pandas para gráfico de tablas y seaborn para mapa de calor de correlación\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# definimos que pandas imprima todas las columnas al mostrar un dataframe\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importanción de anime y users (tablas relativamente cortas)\n",
    "anime = pd.read_csv('anime_cleaned.csv')\n",
    "users = pd.read_csv('users_cleaned.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# la imporanción de animelists es un poco más lenta\n",
    "# por lo que se realiza en otra celda\n",
    "animelists = pd.read_csv('animelists_cleaned.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "animelists_copy = animelists.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              username  anime_id  my_watched_episodes  my_score  my_status  \\\n",
      "6740075  ----phoebelyn       949                    6         0          2   \n",
      "6740012  ----phoebelyn       135                   75         0          2   \n",
      "6740014  ----phoebelyn       153                   45         0          2   \n",
      "6740020  ----phoebelyn       245                   43        10          2   \n",
      "6740026  ----phoebelyn       486                   13         0          2   \n",
      "\n",
      "         my_rewatching  my_rewatching_ep  \n",
      "6740075            0.0                 0  \n",
      "6740012            0.0                 0  \n",
      "6740014            0.0                 0  \n",
      "6740020            0.0                 0  \n",
      "6740026            0.0                 0  \n",
      "Index(['username', 'anime_id', 'my_watched_episodes', 'my_score', 'my_status',\n",
      "       'my_rewatching', 'my_rewatching_ep'],\n",
      "      dtype='object')\n",
      "(19946135, 7)\n"
     ]
    }
   ],
   "source": [
    "print(animelists_copy.head())\n",
    "print(animelists_copy.columns)\n",
    "print(animelists_copy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "animelists_copy = animelists_copy.sort_values(by='username')\n",
    "animelists_copy = animelists_copy.dropna(subset=['username'])\n",
    "animelists_copy = animelists_copy.drop(columns=[\n",
    "    'my_start_date', 'my_finish_date', 'my_tags', 'my_last_updated'\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminar todos los usuarios que no han completado un anime, quedandose solo con los usuarios que si han completado un anime\n",
    "animelists_copy = animelists_copy[animelists_copy[\"my_status\"] == 2]\n",
    "#Dropear todas laanimelists_copys columnas menos 'anime_id' y 'username'\n",
    "gen_clusters = animelists_copy[[\"anime_id\", \"username\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users columns Index(['username', 'user_id', 'user_watching', 'user_completed', 'user_onhold',\n",
      "       'user_dropped', 'user_plantowatch', 'user_days_spent_watching',\n",
      "       'gender', 'location', 'birth_date', 'access_rank', 'join_date',\n",
      "       'last_online', 'stats_mean_score', 'stats_rewatched', 'stats_episodes'],\n",
      "      dtype='object')\n",
      "anime columns Index(['anime_id', 'title', 'title_english', 'title_japanese',\n",
      "       'title_synonyms', 'image_url', 'type', 'source', 'episodes', 'status',\n",
      "       'airing', 'aired_string', 'aired', 'duration', 'rating', 'score',\n",
      "       'scored_by', 'rank', 'popularity', 'members', 'favorites', 'background',\n",
      "       'premiered', 'broadcast', 'related', 'producer', 'licensor', 'studio',\n",
      "       'genre', 'opening_theme', 'ending_theme', 'duration_min',\n",
      "       'aired_from_year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"users columns\", users.columns)\n",
    "print(\"anime columns\", anime.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anime:  (6668, 2)\n"
     ]
    }
   ],
   "source": [
    "#Dropear del dataset 'anime' todas las columnas excepto 'anime' y 'genero'\n",
    "anime = anime.drop(columns=[\n",
    "    'image_url', 'background', 'related', 'premiered', 'broadcast',\n",
    "    'opening_theme', 'ending_theme', 'title_english', 'title_japanese', 'title_synonyms',\n",
    "    'airing', 'aired_string', 'licensor'\n",
    "    ])\n",
    "anime = anime[[\"anime_id\", \"genre\"]]\n",
    "print(\"anime: \",anime.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users:  (108711, 3)\n"
     ]
    }
   ],
   "source": [
    "#Filtrar columnas user_name, genre, y edad\n",
    "users['age'] = 2018 - users['birth_date'].str[:4].astype(int)\n",
    "users = users[[\"username\", \"gender\", \"age\"]]\n",
    "print(\"users: \", users.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_clusters = gen_clusters.merge(anime, on=\"anime_id\", how=\"inner\")\n",
    "gen_clusters = gen_clusters.merge(users, on=\"username\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19946135, 3)\n",
      "Index(['genre', 'gender', 'age'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "gen_clusters = gen_clusters[['genre','gender','age']]\n",
    "print(gen_clusters.shape)\n",
    "print(gen_clusters.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Action', 'Comedy', 'Drama', 'Mecha', 'Military', 'Sci-Fi', 'Shounen', 'Space', 'Game', 'Supernatural', 'Adventure', 'Fantasy', 'Magic', 'School', 'Slice of Life', 'Psychological', 'Romance', 'Shoujo', 'Police', 'Seinen', 'Historical', 'Samurai', 'Super Power', 'Harem', 'Mystery', 'Music', 'Cars', 'Sports', 'Demons', 'Parody', 'Thriller', 'Ecchi', 'Horror', 'Vampire', 'Josei', 'Martial Arts', 'Shoujo Ai', 'Kids', 'Dementia', 'Yuri', 'Shounen Ai', 'Hentai', 'Yaoi']\n"
     ]
    }
   ],
   "source": [
    "# Primero buscamos todos los generos y productores que existen\n",
    "\n",
    "generos = []\n",
    "for lista in gen_clusters['genre']:\n",
    "    if type(lista) == str:\n",
    "        lista = lista.split(', ')\n",
    "        for genero in lista:\n",
    "            if genero not in generos:\n",
    "                generos.append(genero)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert float NaN to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m genero \u001b[39min\u001b[39;00m generos:\n\u001b[0;32m      4\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(genero) \u001b[39m==\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[1;32m----> 5\u001b[0m         gen_clusters_copy[genero] \u001b[39m=\u001b[39m gen_clusters_copy[\u001b[39m'\u001b[39;49m\u001b[39mgenre\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mstr\u001b[39m.\u001b[39;49mcontains(genero)\u001b[39m.\u001b[39;49mastype(\u001b[39mint\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\alvar\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6240\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m   6233\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[0;32m   6234\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[:, i]\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m   6235\u001b[0m         \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns))\n\u001b[0;32m   6236\u001b[0m     ]\n\u001b[0;32m   6238\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   6239\u001b[0m     \u001b[39m# else, only a single dtype is given\u001b[39;00m\n\u001b[1;32m-> 6240\u001b[0m     new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mastype(dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m   6241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mastype\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   6243\u001b[0m \u001b[39m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:448\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mastype\u001b[39m(\u001b[39mself\u001b[39m: T, dtype, copy: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, errors: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m--> 448\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply(\u001b[39m\"\u001b[39;49m\u001b[39mastype\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mdtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n",
      "File \u001b[1;32mc:\\Users\\alvar\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, ignore_failures, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m         applied \u001b[39m=\u001b[39m b\u001b[39m.\u001b[39mapply(f, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    351\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 352\u001b[0m         applied \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(b, f)(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mNotImplementedError\u001b[39;00m):\n\u001b[0;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ignore_failures:\n",
      "File \u001b[1;32mc:\\Users\\alvar\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py:526\u001b[0m, in \u001b[0;36mBlock.astype\u001b[1;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[39mCoerce to the new dtype.\u001b[39;00m\n\u001b[0;32m    510\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[39mBlock\u001b[39;00m\n\u001b[0;32m    523\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    524\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalues\n\u001b[1;32m--> 526\u001b[0m new_values \u001b[39m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[0;32m    528\u001b[0m new_values \u001b[39m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[0;32m    529\u001b[0m newb \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_block(new_values)\n",
      "File \u001b[1;32mc:\\Users\\alvar\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:299\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[1;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[0;32m    296\u001b[0m     \u001b[39mreturn\u001b[39;00m values\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    298\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 299\u001b[0m     new_values \u001b[39m=\u001b[39m astype_array(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    300\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mValueError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m):\n\u001b[0;32m    301\u001b[0m     \u001b[39m# e.g. astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[0;32m    302\u001b[0m     \u001b[39m#  trying to convert to float\u001b[39;00m\n\u001b[0;32m    303\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\alvar\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:230\u001b[0m, in \u001b[0;36mastype_array\u001b[1;34m(values, dtype, copy)\u001b[0m\n\u001b[0;32m    227\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    229\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 230\u001b[0m     values \u001b[39m=\u001b[39m astype_nansafe(values, dtype, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[0;32m    232\u001b[0m \u001b[39m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[0;32m    233\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, np\u001b[39m.\u001b[39mdtype) \u001b[39mand\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\alvar\\anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:170\u001b[0m, in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m    168\u001b[0m \u001b[39mif\u001b[39;00m copy \u001b[39mor\u001b[39;00m is_object_dtype(arr\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m is_object_dtype(dtype):\n\u001b[0;32m    169\u001b[0m     \u001b[39m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[1;32m--> 170\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39;49mastype(dtype, copy\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    172\u001b[0m \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39mcopy)\n",
      "\u001b[1;31mValueError\u001b[0m: cannot convert float NaN to integer"
     ]
    }
   ],
   "source": [
    "gen_clusters_copy = gen_clusters.copy()\n",
    "# Creamos una columna nueva en el dataframe anime por cada gener\n",
    "for genero in generos:\n",
    "    if type(genero) == str:\n",
    "        gen_clusters_copy[genero] = gen_clusters_copy['genre'].str.contains(genero).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## análisis de clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports para realizar el análisis de la pregunta 2 con distintos métodos de clustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import datasets\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import DBSCAN\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
